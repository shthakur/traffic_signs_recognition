{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import optim, nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from argparse import Namespace\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 43\n",
    "IMG_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = Namespace()\n",
    "params.data = './data'\n",
    "params.lr = 0.0001\n",
    "params.batch_size = 64\n",
    "params.seed = 7\n",
    "params.cnn = '100, 150, 250, 350'\n",
    "params.locnet = '200,300,200'\n",
    "params.locnet2 = None\n",
    "params.locnet3 = '150,150,150'\n",
    "params.st = True\n",
    "params.resume = False\n",
    "params.epochs = 100\n",
    "params.patience = 30\n",
    "params.dropout = 0.5\n",
    "params.use_pickle = True\n",
    "params.train_pickle = '/scratch/as10656/traffic/train_extended_preprocessed.p'\n",
    "params.extra_debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.manual_seed(params.seed)\n",
    "torch.manual_seed(params.seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrafficSignsDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = torch.from_numpy(images)\n",
    "        self.images = self.images.permute(0, 3, 1, 2)\n",
    "        self.labels = torch.LongTensor(labels.argmax(1))\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.images[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "class Utils:\n",
    "    def __init__(self):\n",
    "        self.train_data_transforms = transforms.Compose([\n",
    "            transforms.Resize(32, 32)\n",
    "        ])\n",
    "        self.val_data_transforms = transforms.Compose([\n",
    "            transforms.Resize(32, 32)\n",
    "        ])\n",
    "    def load_pickled_data(self, file, columns):\n",
    "        with open(file, mode='rb') as f:\n",
    "            dataset = pickle.load(f)\n",
    "        return tuple(map(lambda c: dataset[c], columns))\n",
    "    \n",
    "    def get_dataset(self, params):\n",
    "        if params.use_pickle:\n",
    "            data_images, data_labels = self.load_pickled_data(params.train_pickle, ['features', 'labels'])\n",
    "            train_images, val_images, train_labels, val_labels = train_test_split(data_images, \n",
    "                                                                                  data_labels, \n",
    "                                                                                  test_size=0.25) \n",
    "            return TrafficSignsDataset(train_images, train_labels), TrafficSignsDataset(val_images, val_labels)\n",
    "        else:\n",
    "            train_dataset = datasets.ImageFolder(params.data + '/train_images',\n",
    "                                                 transform=self.train_data_transforms)\n",
    "            val_dataset = datasets.ImageFolder(self.params.data + '/val_images',\n",
    "                                               transform=self.val_data_transforms)\n",
    "            return train_dataset, val_dataset\n",
    "    def get_convnet_output_size(self, network, input_size=IMG_SIZE):\n",
    "        input_size = input_size or IMG_SIZE\n",
    "\n",
    "        if type(network) != list:\n",
    "            network = [network]\n",
    "\n",
    "        in_channels = network[0].conv.in_channels\n",
    "\n",
    "        output = Variable(torch.ones(1, in_channels, input_size, input_size))\n",
    "        output.require_grad = False\n",
    "        for conv in network:\n",
    "            output = conv.forward(output)\n",
    "\n",
    "        return np.asscalar(np.prod(output.data.shape)), output.data.size()[2]\n",
    "    def get_time_hhmmss(self, start = None):\n",
    "        \"\"\"\n",
    "        Calculates time since `start` and formats as a string.\n",
    "        \"\"\"\n",
    "        if start is None:\n",
    "            return time.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "        end = time.time()\n",
    "        m, s = divmod(end - start, 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        time_str = \"%02d:%02d:%02d\" % (h, m, s)\n",
    "        return time_str  \n",
    "\n",
    "\n",
    "utils = Utils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_c, out_c,\n",
    "                 kernel_size,\n",
    "                 padding_size='same',\n",
    "                 pool_stride=2,\n",
    "                 batch_norm=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if padding_size == 'same':\n",
    "            padding_size = kernel_size // 2\n",
    "        self.conv = nn.Conv2d(in_c, out_c, kernel_size, padding=padding_size)\n",
    "        self.max_pool2d = nn.MaxPool2d(pool_stride, stride=pool_stride)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.batch_norm_2d = nn.BatchNorm2d(out_c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.max_pool2d(nn.functional.leaky_relu(self.conv(x)))\n",
    "\n",
    "        if self.batch_norm:\n",
    "            return self.batch_norm_2d(x)\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_nbr, out_nbr):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.input_nbr = input_nbr\n",
    "        self.lin = nn.Linear(input_nbr, out_nbr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SoftMaxClassifier(Classifier):\n",
    "    def __init__(self, in_len, out_len):\n",
    "        super().__init__(in_len, out_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = super().forward(x)\n",
    "        return nn.functional.log_softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, input_nbr, out_nbr):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.input_nbr = input_nbr\n",
    "        self.lin = nn.Linear(input_nbr, out_nbr)\n",
    "        self.rel = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.dropout(self.rel(self.lin(input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LocalizationNetwork(nn.Module):\n",
    "    nbr_params = 6\n",
    "    init_bias = torch.Tensor([1, 0, 0, 0, 1, 0])\n",
    "\n",
    "    def __init__(self, conv_params, kernel_sizes,\n",
    "                 input_size, input_channels=1):\n",
    "        super(LocalizationNetwork, self).__init__()\n",
    "\n",
    "        if not kernel_sizes:\n",
    "            kernel_sizes = [5, 5]\n",
    "\n",
    "        if len(kernel_sizes) != 2:\n",
    "            raise Exception(\"Number of kernel sizes != 2\")\n",
    "\n",
    "        self.conv1 = ConvNet(input_channels, conv_params[0],\n",
    "                             kernel_size=kernel_sizes[0],\n",
    "                             batch_norm=False)\n",
    "        self.conv2 = ConvNet(conv_params[0], conv_params[1],\n",
    "                             kernel_size=kernel_sizes[1],\n",
    "                             batch_norm=False)\n",
    "        conv_output_size, _ = utils.get_convnet_output_size([self.conv1, self.conv2],\n",
    "                                                            input_size)\n",
    "\n",
    "        self.fc = FullyConnected(conv_output_size, conv_params[2])\n",
    "        self.classifier = Classifier(conv_params[2], self.nbr_params)\n",
    "\n",
    "        self.classifier.lin.weight.data.fill_(0)\n",
    "        self.classifier.lin.bias.data = torch.FloatTensor([1, 0, 0, 0, 1, 0])\n",
    "        self.dropout = nn.Dropout2d()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.conv1(x))\n",
    "        conv_output = self.dropout(self.conv2(x))\n",
    "        conv_output = conv_output.view(conv_output.size()[0], -1)\n",
    "        return self.classifier(self.fc(conv_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialTransformerNetwork(nn.Module):\n",
    "    def __init__(self, params, kernel_sizes, input_size=IMG_SIZE,\n",
    "                 input_channels=1):\n",
    "        super(SpatialTransformerNetwork, self).__init__()\n",
    "        self.localization_network = LocalizationNetwork(params,\n",
    "                                                        kernel_sizes,\n",
    "                                                        input_size,\n",
    "                                                        input_channels)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.localization_network(input)\n",
    "        out = out.view(out.size()[0], 2, 3)\n",
    "        grid = nn.functional.affine_grid(out, input.size())\n",
    "        return nn.functional.grid_sample(input, grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GeneralNetwork(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(GeneralNetwork, self).__init__()\n",
    "\n",
    "        if not opt.cnn:\n",
    "            opt.cnn = '100, 150, 250, 350'\n",
    "        kernel_sizes = [7, 4, 4]\n",
    "        conv_params = list(map(int, opt.cnn.split(\",\")))\n",
    "\n",
    "        self.conv1 = ConvNet(1, conv_params[0], kernel_size=kernel_sizes[0],\n",
    "                             padding_size=0)\n",
    "        self.conv2 = ConvNet(conv_params[0], conv_params[1],\n",
    "                             kernel_size=kernel_sizes[1],\n",
    "                             padding_size=0)\n",
    "\n",
    "        conv_output_size, _ = utils.get_convnet_output_size([self.conv1, self.conv2])\n",
    "\n",
    "        self.fc = FullyConnected(conv_output_size, conv_params[2])\n",
    "        self.classifier = SoftMaxClassifier(conv_params[2], NUM_CLASSES)\n",
    "\n",
    "        self.locnet_1 = None\n",
    "        if opt.st and opt.locnet:\n",
    "            params = list(map(int, opt.locnet.split(\",\")))\n",
    "            self.locnet_1 = SpatialTransformerNetwork(params,\n",
    "                                                      kernel_sizes=[7, 5])\n",
    "\n",
    "        self.locnet_2 = None\n",
    "        if opt.st and opt.locnet2:\n",
    "            params = list(map(int, opt.locnet2.split(\",\")))\n",
    "            _, current_size = utils.get_convnet_output_size([self.conv1])\n",
    "            self.locnet_2 = SpatialTransformerNetwork(params,\n",
    "                                                      [5, 3],\n",
    "                                                      current_size,\n",
    "                                                      conv_params[0])\n",
    "        self.dropout = nn.Dropout2d()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.locnet_1:\n",
    "            x = self.locnet_1(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        if self.locnet_2:\n",
    "            x = self.locnet_2(x)\n",
    "\n",
    "        return self.classifier(self.fc(self.dropout(self.conv2(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IDSIANetwork(GeneralNetwork):\n",
    "    def __init__(self, opt):\n",
    "        super().__init__(opt)\n",
    "        conv_params = list(map(int, opt.cnn.split(\",\")))\n",
    "\n",
    "        self.conv3 = ConvNet(conv_params[1], conv_params[2], kernel_size=4,\n",
    "                             padding_size=0)\n",
    "        conv_output_size, _ = utils.get_convnet_output_size([self.conv1,\n",
    "                                                      self.conv2,\n",
    "                                                      self.conv3])\n",
    "        self.fc = FullyConnected(conv_output_size, conv_params[3])\n",
    "        self.classifier = SoftMaxClassifier(conv_params[3], NUM_CLASSES)\n",
    "\n",
    "        self.locnet_3 = None\n",
    "        if opt.st and opt.locnet3:\n",
    "            params = list(map(int, opt.locnet3.split(\",\")))\n",
    "            _, current_size = utils.get_convnet_output_size([self.conv1, self.conv2])\n",
    "            self.locnet_3 = SpatialTransformerNetwork(params,\n",
    "                                                      [3, 3],\n",
    "                                                      current_size,\n",
    "                                                      conv_params[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.locnet_1:\n",
    "            x = self.locnet_1(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        if self.locnet_2:\n",
    "            x = self.locnet_2(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        if self.locnet_3:\n",
    "            x = self.locnet_3(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        return self.classifier(self.fc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    def __init__(self, model, optimizer, patience = 100, minimize = True):\n",
    "        self.minimize = minimize\n",
    "        self.patience = patience\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.best_monitored_value = np.inf if minimize else 0.\n",
    "        self.best_monitored_acc = 0. if minimize else np.inf\n",
    "        self.best_monitored_epoch = 0\n",
    "\n",
    "        self.restore_path = None\n",
    "\n",
    "    def __call__(self, value, acc, epoch, rest):\n",
    "        if (self.minimize and value < self.best_monitored_value) or (not self.minimize and value > self.best_monitored_value):\n",
    "            self.best_monitored_value = value\n",
    "            self.best_monitored_epoch = epoch\n",
    "            self.best_monitored_acc = acc\n",
    "            state = {\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': self.model.state_dict(),\n",
    "                'best': value,\n",
    "                'best_acc': acc,\n",
    "                'optimizer': self.optimizer.state_dict(),\n",
    "            }            \n",
    "            \n",
    "            state.update(rest)\n",
    "            self.restore_path = utils.save_checkpoint(state, True, \"/scratch/as10656/nli-models/early_stopping_checkpoint\")\n",
    "        elif self.best_monitored_epoch + self.patience < epoch:\n",
    "            if self.restore_path != None:\n",
    "                checkpoint = utils.load_checkpoint(self.restore_path)\n",
    "                self.best_monitored_value = checkpoint['best']\n",
    "                self.best_monitored_acc = checkpoint['best_acc']\n",
    "                self.best_monitored_epoch = checkpoint['epoch']\n",
    "                self.model.load_state_dict(checkpoint['state_dict'])\n",
    "                self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            else:\n",
    "                print(\"ERROR: Failed to restore session\")\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def init_from_checkpoint(self, checkpoint):\n",
    "        self.best_monitored_value = checkpoint['best']\n",
    "        self.best_monitored_acc = checkpoint['best_acc']\n",
    "        self.best_monitored_epoch = 0\n",
    "    \n",
    "    def print_info(self):\n",
    "        print(\"Best loss: {0}, Best Accuracy: {1}, at epoch {2}\"\n",
    "              .format(self.best_monitored_value,\n",
    "                      self.best_monitored_acc,\n",
    "                      self.best_monitored_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_curve(axis, params, train_column, valid_column, linewidth = 2, train_linestyle = \"b-\", valid_linestyle = \"g-\"):\n",
    "    \"\"\"\n",
    "    Plots a pair of validation and training curves on a single plot.\n",
    "    \"\"\"\n",
    "    train_values = params[train_column]\n",
    "    valid_values = params[valid_column]\n",
    "    epochs = train_values.shape[0]\n",
    "    x_axis = np.arange(epochs)\n",
    "    axis.plot(x_axis[train_values > 0], train_values[train_values > 0], train_linestyle, linewidth=linewidth, label=\"train\")\n",
    "    axis.plot(x_axis[valid_values > 0], valid_values[valid_values > 0], valid_linestyle, linewidth=linewidth, label=\"valid\")\n",
    "    return epochs\n",
    "\n",
    "# Plots history of learning curves for a specific model.\n",
    "def plot_learning_curves(params):\n",
    "    \"\"\"\n",
    "    Plots learning curves (loss and accuracy on both training and validation sets) for a model identified by a parameters struct.\n",
    "    \"\"\"\n",
    "    curves_figure = plt.figure(figsize = (10, 4))\n",
    "    axis = curves_figure.add_subplot(1, 2, 1)\n",
    "    epochs_plotted = plot_curve(axis, params, train_column = \"train_acc\", valid_column = \"val_acc\")\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.ylim(50., 115.)\n",
    "    plt.xlim(0, epochs_plotted)\n",
    "\n",
    "    axis = curves_figure.add_subplot(1, 2, 2)\n",
    "    epochs_plotted = plot_curve(axis, params, train_column = \"train_loss\", valid_column = \"val_loss\")\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.ylim(0.0001, 10.)\n",
    "    plt.xlim(0, epochs_plotted)\n",
    "    plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, params, train_data, val_data):\n",
    "        self.params = params\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.epochs = params.epochs\n",
    "        print(\"Creating dataloaders\")\n",
    "        self.cuda_available = torch.cuda.is_available()\n",
    "        \n",
    "        self.train_loader = DataLoader(dataset=train_data,\n",
    "                                       shuffle=True,\n",
    "                                       batch_size=params.batch_size,\n",
    "                                       pin_memory=self.cuda_available)\n",
    "        self.val_loader = DataLoader(dataset=val_data,\n",
    "                                     shuffle=False,\n",
    "                                     batch_size=params.batch_size,\n",
    "                                     pin_memory=self.cuda_available)\n",
    "        \n",
    "        self.string_fixer = \"==========\"\n",
    "\n",
    "        \n",
    "    def train(self):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        model = IDSIANetwork(self.params)\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad,\n",
    "                                      model.parameters()),\n",
    "                               lr=params.lr)\n",
    "\n",
    "        start_epoch = 0\n",
    "        best_prec = 0\n",
    "        self.start_time = time.time()\n",
    "        self.histories = {\n",
    "            \"train_loss\": np.empty(0, dtype=np.float32),\n",
    "            \"train_acc\": np.empty(0, dtype=np.float32),\n",
    "            \"val_loss\": np.empty(0, dtype=np.float32),\n",
    "            \"val_acc\": np.empty(0, dtype=np.float32)\n",
    "        }\n",
    "        \n",
    "        \n",
    "        self.early_stopping = EarlyStopping(model, optimizer, patience=self.params.patience)\n",
    "        if self.params.resume:\n",
    "            checkpoint = utils.load_checkpoint(self.params.resume)\n",
    "            if checkpoint is not None:\n",
    "                model.load_state_dict(checkpoint['state_dict'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "                self.histories.update(checkpoint)\n",
    "                self.early_stopping.init_from_checkpoint(checkpoint)\n",
    "                print(\"Loaded model, Best Loss: %.8f, Best Acc: %.2f\" % (checkpoint['best'], checkpoint['best_acc']))\n",
    "\n",
    "        is_best = False\n",
    "\n",
    "        if self.cuda_available:\n",
    "            model = model.cuda()\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        model.train()\n",
    "        print(\"Starting training\")\n",
    "        self.print_info()\n",
    "        for epoch in range(start_epoch, params.epochs):\n",
    "            for i, (images, labels) in enumerate(self.train_loader):\n",
    "                images_batch = Variable(images)\n",
    "                labels_batch = Variable(labels)\n",
    "\n",
    "                if self.cuda_available:\n",
    "                    images_batch = images_batch.cuda()\n",
    "                    labels_batch = labels_batch.cuda(async=True)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(images_batch)\n",
    "                loss = criterion(output, labels_batch.long())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if self.params.extra_debug and (i + 1) % (self.params.batch_size * 4) == 0:\n",
    "                    print(('Epoch: [{0}/{1}], Step: [{2}/{3}], Loss: {4},')\n",
    "                             .format(epoch + 1,\n",
    "                                     self.params.epochs,\n",
    "                                     i + 1,\n",
    "                                     len(self.train_loader),\n",
    "                                     loss.data[0]))\n",
    "            \n",
    "            train_acc, train_loss = self.validate_model(self.train_loader, model)\n",
    "            val_acc, val_loss = self.validate_model(self.val_loader, model)\n",
    "            \n",
    "            self.histories['train_loss'] = np.append(self.histories['train_loss'], [train_loss])\n",
    "            self.histories['val_loss'] = np.append(self.histories['val_loss'], [val_loss])\n",
    "            self.histories['val_acc'] = np.append(self.histories['val_acc'], [val_acc])\n",
    "            self.histories['train_acc'] = np.append(self.histories['train_acc'], [train_acc])\n",
    "            \n",
    "            if not self.early_stopping(val_loss, val_acc, epoch, self.histories):\n",
    "                self.print_train_info(epoch, train_acc, train_loss, val_acc, val_loss)\n",
    "            else:\n",
    "                print(\"Early stopping activated\")\n",
    "                print(\"Restoring earlier state and stopping\")\n",
    "                self.early_stopping.print_info()\n",
    "                plot_learning_curves(self.histories)\n",
    "                plt.show()\n",
    "                break\n",
    "            \n",
    "\n",
    "            \n",
    "    def validate_model(self, loader, model):\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_loss = 0\n",
    "\n",
    "        for images, hypo, labels in loader:\n",
    "            images_batch = Variable(images, volatile=True)\n",
    "            labels_batch = Variable(labels.long())\n",
    "\n",
    "            if self.cuda_available:\n",
    "                images_batch = images_batch.cuda()\n",
    "                labels_batch = labels_batch.cuda()\n",
    "\n",
    "            output = model(images_batch, hypo_batch)\n",
    "            loss = nn.functional.cross_entropy(output, labels_batch.long(), size_average=False)\n",
    "            total_loss += len(images_batch) * loss.data\n",
    "            total += len(labels_batch)\n",
    "            \n",
    "            if not self.cuda_available:\n",
    "                correct += (labels_batch == output.max(1)[1]).data.cpu().numpy().sum()\n",
    "            else:\n",
    "                correct += (labels_batch == output.max(1)[1]).data.sum()\n",
    "                \n",
    "        model.train()\n",
    "\n",
    "        average_loss = total_loss[0] / total\n",
    "        return correct / total * 100, average_loss\n",
    "\n",
    "    def print_info(self):\n",
    "        print(self.string_fixer + \" Data \" + self.string_fixer)\n",
    "        print(\"Training set: %d examples\" % (len(self.train_data)))\n",
    "        print(\"Validation set: %d examples\" % (len(self.val_data)))\n",
    "        print(\"Timestamp: %s\" % utils.get_time_hhmmss())\n",
    "        \n",
    "        print(self.string_fixer + \" Params \" + self.string_fixer)\n",
    "    \n",
    "        print(\"Learning Rate: %f\" % self.params.lr)\n",
    "        print(\"Dropout (p): %f\" % self.params.dropout)\n",
    "        print(\"Batch Size: %d\" % self.params.batch_size)\n",
    "        print(\"Epochs: %d\" % self.params.epochs)\n",
    "        print(\"Patience: %d\" % self.params.patience)\n",
    "        print(\"Resume: %s\" % self.params.resume)\n",
    "        \n",
    "    def print_train_info(self, epoch, train_acc, train_loss, val_acc, val_loss):\n",
    "        print((self.string_fixer + \" Epoch: {0}/{1} \" + self.string_fixer)\n",
    "              .format(epoch + 1, self.params.epochs))\n",
    "        print(\"Train Loss: %.8f, Train Acc: %.2f\" % (train_loss, train_acc))\n",
    "        print(\"Validation Loss: %.8f, Validation Acc: %.2f\" % (val_loss, val_acc))\n",
    "        self.early_stopping.print_info()\n",
    "        print(\"Elapsed Time: %s\" % (utils.get_time_hhmmss(self.start_time)))\n",
    "        print(\"Current timestamp: %s\" % (utils.get_time_hhmmss()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = utils.get_dataset(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataloaders\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(params, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "========== Data ==========\n",
      "Training set: 521985 examples\n",
      "Validation set: 173995 examples\n",
      "Timestamp: 2017/11/20 16:46:08\n",
      "========== Params ==========\n",
      "Learning Rate: 0.000100\n",
      "Dropout (p): 0.500000\n",
      "Batch Size: 64\n",
      "Epochs: 100\n",
      "Patience: 30\n",
      "Resume: False\n",
      "Epoch: [1/100], Step: [256/8157], Loss: 3.5578806400299072,\n",
      "Epoch: [1/100], Step: [512/8157], Loss: 3.469850778579712,\n",
      "Epoch: [1/100], Step: [768/8157], Loss: 3.562333583831787,\n",
      "Epoch: [1/100], Step: [1024/8157], Loss: 3.5242562294006348,\n",
      "Epoch: [1/100], Step: [1280/8157], Loss: 3.643771171569824,\n",
      "Epoch: [1/100], Step: [1536/8157], Loss: 3.514530897140503,\n",
      "Epoch: [1/100], Step: [1792/8157], Loss: 3.372837781906128,\n",
      "Epoch: [1/100], Step: [2048/8157], Loss: 3.5515120029449463,\n",
      "Epoch: [1/100], Step: [2304/8157], Loss: 3.4567337036132812,\n",
      "Epoch: [1/100], Step: [2560/8157], Loss: 3.5267200469970703,\n",
      "Epoch: [1/100], Step: [2816/8157], Loss: 3.4223105907440186,\n",
      "Epoch: [1/100], Step: [3072/8157], Loss: 3.483168601989746,\n",
      "Epoch: [1/100], Step: [3328/8157], Loss: 3.5433664321899414,\n",
      "Epoch: [1/100], Step: [3584/8157], Loss: 3.568814516067505,\n",
      "Epoch: [1/100], Step: [3840/8157], Loss: 3.3914380073547363,\n",
      "Epoch: [1/100], Step: [4096/8157], Loss: 3.38934326171875,\n",
      "Epoch: [1/100], Step: [4352/8157], Loss: 3.5348193645477295,\n",
      "Epoch: [1/100], Step: [4608/8157], Loss: 3.4644291400909424,\n",
      "Epoch: [1/100], Step: [4864/8157], Loss: 3.4832305908203125,\n",
      "Epoch: [1/100], Step: [5120/8157], Loss: 3.592407464981079,\n",
      "Epoch: [1/100], Step: [5376/8157], Loss: 3.541106700897217,\n",
      "Epoch: [1/100], Step: [5632/8157], Loss: 3.6171762943267822,\n",
      "Epoch: [1/100], Step: [5888/8157], Loss: 3.344381093978882,\n",
      "Epoch: [1/100], Step: [6144/8157], Loss: 3.3963418006896973,\n",
      "Epoch: [1/100], Step: [6400/8157], Loss: 3.6162149906158447,\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
